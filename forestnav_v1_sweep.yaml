program: train_ppo.py
command:
  - ${interpreter}
  - ${program}
  - ${args_no_boolean_flags}
method: grid
name: parameter_sweep
metric:
  name: eval/episode_reward
  goal: maximize
parameters:
  # Parameters to sweep
  reward_scaling:
    value: 1
  learning_rate:
    value: 3e-4
  entropy_cost:
    values: [1e-3, 1e-2, 0.1, 0.5, 0.8, 1.0]
  num_minibatches:
    value: 128
  batch_size:
    value: 8
  normalize_observations:
    values:
      - false

  # Fixed parameters
  num_timesteps:
    value: 20000000
  num_evals:
    value: 20
  episode_length:
    value: 400
  unroll_length:
    value: 40
  num_updates_per_batch:
    value: 4
  num_envs:
    value: 512
  seed:
    value: 0
  action_repeat:
    value: 1
  discounting:
    value: 0.99